{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "Describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LORA\n",
    "* Model: distilbert-base-uncased\n",
    "* Evaluation approach: F1 and Accuracy\n",
    "* Fine-tuning dataset: IMDB from HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "Load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c1cf30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp38-cp38-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pouya\\venv\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pouya\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pouya\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pouya\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pouya\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pouya\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\pouya\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pouya\\venv\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pouya\\venv\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pouya\\venv\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pouya\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pouya\\venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp38-cp38-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "Successfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pouya\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pouya\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pouya\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pouya\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|█████████████████████████████████████████| 25000/25000 [00:00<00:00, 145897.97 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████| 25000/25000 [00:00<00:00, 156302.55 examples/s]\n",
      "Generating unsupervised split: 100%|██████████████████████████████████| 50000/50000 [00:00<00:00, 145739.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## load IMDB Dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a54fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 3000/3000 [00:02<00:00, 1083.98 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 600/600 [00:00<00:00, 1245.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocessor, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocessor, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2e78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the text column as it's no longer needed\n",
    "tokenized_train = tokenized_train.remove_columns([\"text\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"text\"])\n",
    "\n",
    "# Rename 'label' to 'labels' for the trainer\n",
    "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
    "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2888c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean(), \"f1\": f1_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "622c607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating base model performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouya\\AppData\\Local\\Temp\\ipykernel_33112\\2159945670.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 05:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6996585726737976,\n",
       " 'eval_model_preparation_time': 0.0025,\n",
       " 'eval_accuracy': 0.51,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_runtime': 318.8407,\n",
       " 'eval_samples_per_second': 1.882,\n",
       " 'eval_steps_per_second': 0.235}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Evaluate the base model\n",
    "print(\"\\nEvaluating base model performance...\")\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_trainer.evaluate(eval_dataset=tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 67,842,052 || trainable%: 1.3075\n"
     ]
    }
   ],
   "source": [
    "# Create LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=16,  # rank\n",
    "    lora_alpha=32,  # LoRA scaling parameter\n",
    "    lora_dropout=0.1,  # LoRA dropout\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],  # DistilBERT specific modules\n",
    ")\n",
    "\n",
    "# Create PEFT model\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting PEFT training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pouya\\venv\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\pouya\\AppData\\Local\\Temp\\ipykernel_33112\\711867522.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "2025/05/29 13:43:01 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 2f478916ff424dcc85c87928d424bf13: Failed to log run data: Exception: Changing param values is not allowed. Param with key='output_dir' was already logged with value='tmp_trainer' for run ID='2f478916ff424dcc85c87928d424bf13'. Attempted logging new value './tmp/'.\n",
      "2025/05/29 13:43:01 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 2f478916ff424dcc85c87928d424bf13: Failed to log run data: Exception: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='tmp_trainer\\runs\\May29_13-37-40_LAPTOP-42KG8MRA' for run ID='2f478916ff424dcc85c87928d424bf13'. Attempted logging new value './tmp/runs\\May29_13-42-59_LAPTOP-42KG8MRA'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='195' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [195/376 1:13:13 < 1:08:40, 0.04 it/s, Epoch 1.03/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.289800</td>\n",
       "      <td>0.304616</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.863481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tmp/\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nStarting PEFT training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "peft_model.save_pretrained(\"/tmp/peft_lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "Load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the model\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "reloaded_model = AutoPeftModelForSequenceClassification.from_pretrained(\"/tmp/peft_lora_model\")\n",
    "reloaded_model = reloaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the PEFT model\n",
    "peft_trainer = Trainer(\n",
    "    model=reloaded_model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "peft_results = peft_trainer.evaluate(eval_dataset=tokenized_test)\n",
    "peft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
